<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Java | Chris's Blog]]></title>
  <link href="http://askcuix.github.com/blog/categories/java/atom.xml" rel="self"/>
  <link href="http://askcuix.github.com/"/>
  <updated>2013-04-01T23:58:34+08:00</updated>
  <id>http://askcuix.github.com/</id>
  <author>
    <name><![CDATA[Chris]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[The foundation of spring batch]]></title>
    <link href="http://askcuix.github.com/blog/2013/04/01/the-foundation-of-spring-batch/"/>
    <updated>2013-04-01T22:46:00+08:00</updated>
    <id>http://askcuix.github.com/blog/2013/04/01/the-foundation-of-spring-batch</id>
    <content type="html"><![CDATA[<p>Spring Batch是埃森哲贡献给Spring的一个开源项目，现在由双方共同维护。通过Spring Batch可以构建出轻量级的大数据量并⾏处理应⽤,⽀持事务、并发、流程、监控、纵向和横向扩展,提供统一的接口管理。Spring Batch并不包含scheduler，它只是一个通用的batch处理框架，你可以通过QuartZ，Control-M等scheduler去调用。</p>

<p>Spring Batch能够处理大批量数据的导入、导出和业务逻辑计算，执行过程无需人工干预。我们的系统是一个金融产品信息的数据中心，需要从不同的系统读取产品信息，也需要将这些信息提供给其它的系统，这种data loading就是Spring Batch的一种应用场景。</p>

<!-- more -->


<p><img src="/images/blog/spring_batch_common_process.png" alt="Spring Batch Common Process" /></p>

<p>上图就是Spring Batch的常用方式，从DB或是不同类型的文件中读取数据，经过转换后再写入DB或者文件。</p>

<p><img src="/images/blog/spring_batch_domain.png" alt="Spring Batch Domain" /></p>

<p>上图是一个Job执行的结构图，下面是对这些domain对象的简单描述，只是学习时随笔记下来的，不够详细，可以查看Spring Batch文档中的描述。</p>

<h2>Job</h2>

<p>Job是对一个batch处理流程的定义，可以简单理解为Spring中的一个Job配置，一般都包括reader和writer。</p>

<h2>JobInstance</h2>

<p>JobInstance是Job运行时产生的实例，如果这个Job是按天执行的，则每天都会创建一个JobInstance；当Job执行失败时，restart这个Job将会重用JobInstance，以便于从执行失败的地方开始重新执行。</p>

<h2>JobParameter</h2>

<p>JobParameter用于标识一个JobInstance，可以将它理解为JobInstance的ID。</p>

<h2>JobListener</h2>

<p>JobListener可以监听JobInstance生命周期中的两个事件：</p>

<p><strong>beforeJob</strong> - 在Job执行前被调用。</p>

<p><strong>afterJob</strong> - 不论Job执行成功或失败都会被调用，Job的status可以从JobExecution中获取。</p>

<h2>Parent Job</h2>

<p>对于相似的Job，可以取出相同的部分定义成一个parent Job，只需要在Job定义时添加<em>abstract="true"</em>，然后在sub Job中通过<em>parent</em>属性来指定parent Job。</p>

<h2>JobRepository</h2>

<p>MapJobRepository通常用于测试环境或是standalone的batch。它不够稳定；不允许在不同JVM实例之间执行restart；也不能保证有相同JobParameter的两个JobInstance同时运行；它不适合在多线程Job或本地的partition step中使用。但是它仍然需要配置transaction manager，因为在Job的实现中会涉及到rollback的问题，所以可以用ResourcelessTransactionManager来代替。</p>

<h2>JobLauncher</h2>

<p>JobLauncher使用spring的taskExecutor来实现异步处理，只需要在配置中指定taskExecutor属性。如果batch是通过http request的方式触发的，那应当使用异步的方式来处理Job以避免长时间的占用链接。</p>

<h2>JobOperator</h2>

<p>JobOperator的stop()不会立刻停止一个Job，如果当前流程处理的控制权在framework，则会将StepExecution的status设置为STOPPED并保存，然后按正常的处理流程结束Job。</p>

<p>如果不希望一个restartable的Job在执行失败后restart，可以将status设置为ABORTED。</p>

<h2>JobParametersIncrementer</h2>

<p>JobParametersIncrementer可强制创建一个新的jobInstance，以避免在使用相同JobParameter时不可以再次执行Job。这只是个接口，需要自己去实现getNext()，然后在Job中定义incremented属性来引用它。</p>

<h2>Step</h2>

<p><strong>start-limit</strong>： 用于step的restart，用来控制一个start的次数。默认是Integer.MAX_VALUE。<br/>
<strong>allow-start-if-complete</strong>： 强制执行step，不管之前执行成功或失败。</p>

<h3>Skip</h3>

<p>通过指定exception来决定是否skip有问题的数据，可以结合include和exclude来定义exception列表。</p>

<p><strong>skip-limit</strong>：用来控制允许skip的数据的最大数量，在step execution中分别保存有针对read，process和write中skip的数量。</p>

<h3>Retry</h3>

<p>通过指定exception来指定是否允许重试当前有问题的错误数据，对于一些通过重试可以解决问题的数据是非常有用的，比如更新当前数据到DB时，该条数据被其它进程lock了，则在重试时可能就可以正常更新了。</p>

<p><strong>retry-limit</strong>：用来控制每个item允许重试的次数。</p>

<h3>Rollback</h3>

<p>通过指定exception来忽略rollback操作。对于Skip和Retry，如果Exception是由ItemWriter抛出的，则step中被当前transaction控制的数据会被rollback，因此要配合使用no-rollback-exception-classes来决定是否应该执行rollback。</p>

<p>Step通常会缓存Reader读入的数据，如果发生了rollback则不需要重新读入数据，但是对于一些基于transaction资源的Reader，比如从JMS queue中读取数据的Reader，JMS message也会执行rollback，则需要通过is-reader-transactional-queue来标识不需要缓存读入数据。</p>

<h2>ItemStream</h2>

<p>在Step执行失败需要restart时，可以通过ItemStream获取存储在execution之间状态信息。如果ItemReader，ItemProcessor或者ItemWriter实现了ItemStream接口，则会自动被注册在Spring Context中；否则需要单独注册streams。对于CompositeItemWriter，如果delegate的ItemWriter实现了ItemStream接口，也需要主动注册。</p>

<h2>StepListener</h2>

<p>和ItemStream一样，如果ItemReader，ItemProcessor或者ItemWriter实现了StepListener接口，则会被自动注册。</p>

<h3>StepExecutionListener</h3>

<p><strong>beforeStep</strong> - 在step执行之前调用。<br/>
<strong>afterStep</strong> - 在step结束时调用，不管执行成功或失败。可以在这里更改ExitStatus。</p>

<h3>ChunkListener</h3>

<p><strong>beforeChunk</strong> - 被调用在transaction开始后，但在ItemReader的read方法执行前。<br/>
<strong>afterChunk</strong> - chunk被commit/rollback后被调用。</p>

<p>ChunkListener也可被用在未使用chunk方式的step中，比如Tasklet， 会在tasklet执行前后被调用。</p>

<h3>ItemReadListener</h3>

<p><strong>beforeRead</strong> - 在read方法执行前被调用。<br/>
<strong>afterRead</strong> - 在read方法执行成功后被调用，并返回读到的item作为参数。<br/>
<strong>onReadError</strong> -  在read方法出现异常时被调用，并提供异常的类型作为参数。</p>

<h3>ItemProcessListener</h3>

<p><strong>beforeProcess</strong> - 在ItemProcessor的process方法执行前被调用。<br/>
<strong>afterProcess</strong> - 在process方法执行成功后被调用。<br/>
<strong>onProcessError</strong> - 在process方法出现异常时被调用，并提供item和异常作为参数。</p>

<h3>ItemWriteListener</h3>

<p><strong>beforeWrite</strong> - 在ItemWriter的write方法执行前被调用。<br/>
<strong>afterWrite</strong> - 在ItemWriter的write方法执行成功后被调用。<br/>
<strong>onWriteError</strong> - 在ItemWriter的write方法出现异常时被调用，并提供chunk data和异常作为参数。</p>

<h3>SkipListener</h3>

<p><strong>onSkipInRead</strong> - 当item在读取阶段skip时被调用。 <br/>
<strong>onSkipInProcess</strong> - 当item在process阶段skip时被调用。<br/>
<strong>onSkipInWrite</strong> -  当item在写入阶段skip时被调用，并且在transaction被commit之前。</p>

<h2>Resources</h2>

<p>Official site: <a href="http://www.springsource.org/spring-batch">http://www.springsource.org/spring-batch</a></p>

<p>IBM DeveloperWorks - 使用 Spring Batch 构建企业级批处理应用:<br/>
 - <a href="http://www.ibm.com/developerworks/cn/java/j-lo-springbatch1/">http://www.ibm.com/developerworks/cn/java/j-lo-springbatch1/</a><br/>
 - <a href="http://www.ibm.com/developerworks/cn/java/j-lo-springbatch2/">http://www.ibm.com/developerworks/cn/java/j-lo-springbatch2/</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Common Format of CSV Files]]></title>
    <link href="http://askcuix.github.com/blog/2013/03/26/common-format-of-csv-files/"/>
    <updated>2013-03-26T23:43:00+08:00</updated>
    <id>http://askcuix.github.com/blog/2013/03/26/common-format-of-csv-files</id>
    <content type="html"><![CDATA[<p>CSV是一种常见的文件格式，常用于不同系统之间的数据交换，对于该文件格式可以简单描述为：一组使用逗号“,”分隔字段，并以换行符作为一行数据结束的数据集合。该文件可以使用Microsoft Excel查看，但是中文字符会显示为乱码。</p>

<p>这个描述就真的只是简单描述，实际上CSV的格式处理没有这么简单。最近在和另外一个系统做集成，我们的系统会提供CSV数据文件给对方系统处理，由于我们系统中个别字段会包括换行符“CRLF”（这是遗留系统，就不用纠结为什么字段中会包含换行符了），也就是说一个字段可能会显示在几行上，但是这个字段是包含在双引号中的，结果对方系统就处理不了了。因为对方系统只是简单的按行处理数据，用逗号解析字段。</p>

<!-- more -->


<p>这种解析方式通常是没有问题，但是是不完整的。<a href="http://tools.ietf.org/html/rfc4180"><strong>RFC 4180</strong></a>是CSV格式的标准，这里提到并没有官方的规范去定义CSV的格式到底是怎样的，但是根据大多数的实现来看，应该有如下格式：</p>

<ul>
<li><p>每条数据用换行符（CRLF）分割。</p></li>
<li><p>最后一条数据可以不包含换行符。</p></li>
<li><p>可选的header行，如有的话，应该出现在第一行，并且与下面的数据有相同数量的字段。</p></li>
<li><p>在header和每条数据中，使用逗号“,”分隔字段，每一行都应该包含相同数量的字段，空白字符也可作为一个字段，一条数据的最后一个字段不应添加逗号分隔符。</p></li>
<li><p>每个字段可以包含在双引号中。</p></li>
<li><p>如果字段中包含换行符（CRLF），双引号和逗号，则必须将字段包含在双引号中。</p></li>
<li><p>如果字段中包含双引号，则除了需要将字段包含在双引号中，还要在字段中的双引号前再加一个双引号作为转义。</p></li>
</ul>


<p>由此可见，字段中是允许出现换行符的，只要该字段是包含在双引号中的。我也查阅了Spring Batch的CSV Reader的实现，也考虑到了该问题，在发现换行符的同时，也会检查当前字段是否已结束。</p>

<p>因此，我们在生成或解析CSV文件时，应该要考虑到以上特殊字符的处理，在apache的common-lang包中，也有专门针对CSV字符的转义方法，可参考<a href="http://commons.apache.org/proper/commons-lang/javadocs/api-release/org/apache/commons/lang3/StringEscapeUtils.html">StringEscapeUtils</a>，在最大程度上保证系统的robust。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[JVM运行时内存区域]]></title>
    <link href="http://askcuix.github.com/blog/2013/03/26/the-runtime-memory-of-jvm/"/>
    <updated>2013-03-26T23:31:00+08:00</updated>
    <id>http://askcuix.github.com/blog/2013/03/26/the-runtime-memory-of-jvm</id>
    <content type="html"><![CDATA[<p>Java虚拟机管理的运行时数据区域：</p>

<ul>
<li><p>程序计数器</p>

<p>是当前线程所执行的字节码的行号指示器。每条线程都有一个独立的程序计数器，各线程之间的计数器互不影响，该内存区域为线程私有，也不会出现OutOfMemoryError。</p></li>
<li><p>Java虚拟机栈</p>

<p>该区域也是线程私有，其生命周期与线程相同。虚拟机栈表述的是Java方法执行的内存模型：每个方法被执行的时候都会同时创建一个栈帧用于存储局部变量表、操作数栈、动态链接、方法出口等信息。一个方法被调用直至执行完成的过程，就对应着一个栈帧在虚拟机栈中从入栈到出栈的过程。</p>

<p><!-- more --></p>

<p>局部变量表存放了编译期可知的基本类型、对象引用（可能是一个指向对象起始地址的指针，也可能是指向一个对象的句柄，或者是与此对象相关的位置）和retuanAddress类型。64位长度的long和double类型占用2个局部变量空间，其余类型只占用1个。局部变量表所需的内存空间在编译期间完成分配，方法运行期间不会改变。</p>

<p>在本区域中，若线程请求的栈深度大于虚拟机所允许的深度，将抛出StackOverflowError；若动态扩展无法申请到足够的内存时抛出OutOfMemoryError。</p></li>
<li><p>本地方法栈</p>

<p>与虚拟机栈的作用相似，区别是虚拟机栈为虚拟机执行Java方法服务，本地方法栈为虚拟机使用到的Native方法服务。有的虚拟机实现会将虚拟机栈和本地方法栈合在一起。</p></li>
<li><p>Java堆</p>

<p>可被所有线程共享，在虚拟机启动时创建。此区域只用于存放对象实例，是垃圾收集器管理的主要区域。堆的扩展可通过-Xmx和-Xms控制。若堆中没有内存完成实例分配，也无法扩展时，将抛出OutOfMemoryError。</p></li>
<li><p>方法区</p>

<p>可被所有线程共享，用于存放已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。虚拟机规范将方法区描述为堆的一个逻辑部分。该区域很少进行垃圾回收的操作。</p>

<p>若方法区无法满足内存分配需求时，将抛出OutOfMemoryError。</p></li>
</ul>


<h2>对象访问方式</h2>

<p>虚拟机规范中未定义对象访问的方式，在主要的虚拟机实现中包含如下两种方式：</p>

<ul>
<li><p>句柄访问</p>

<p>在Java堆中划分出一块内存作为句柄池，Java栈中对象引用存储的就是对象的句柄地址，句柄中包含了对象实例数据和类型数据的地址信息。</p>

<p>这种方式在对象引用中存储的是稳定的句柄地址，在对象被移动时只会改变句柄中的实例数据指针，对象引用本身不需要被修改。</p></li>
<li><p>指针访问</p>

<p>Java栈中对象引用存储的就是对象的地址。这种方法的访问速度更快，节省了一次指针定位的开销。</p></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Supplementary Characters in Java]]></title>
    <link href="http://askcuix.github.com/blog/2013/03/15/supplementary-characters-in-java/"/>
    <updated>2013-03-15T23:37:00+08:00</updated>
    <id>http://askcuix.github.com/blog/2013/03/15/supplementary-characters-in-java</id>
    <content type="html"><![CDATA[<p>工作中经常会涉及到文件处理，而fixlength类型的文件又是一种很常见的格式。众所周知，fixlength类型的数据就是每个字段对应一行数据中固定长度的字符，每个字段都有对应的start offset和end offset，用实现来表示就是String.substring(start, end)，所以start和end的位置是至关重要的，一个字段对应错了，后面的字段就全错了。</p>

<p>在Java中使用UTF-16来表示unicode字符，一个字符就是16 bit，像String.length()就是返回有多少个16 bit。unicode支持的字符的code point范围是U+0000到U+10FFFF，这其中包括基本字符（BMP）和补充字符（supplementary character），基本字符时从U+0000到U+FFFF，补充字符从U+10000到U+10FFFF。<!-- more -->在UTF-16编码中，基本字符占用一个16 bit，而补充字符占用两个16 bit。这样Java String的很多方法就会出现问题了，当然也包括上面提到的substring和length。那么如果fixlength文件中含有补充字符，则会导致字段map错误。</p>

<p>那现在来看如何解决这个问题，一个解决办法是对字符串做Base64编码，编码之后的字符都是单个16 bit了。但是这有两个弊端，一是Base64之后会使数据变大，有时我们会将这些fixlength的数据作为JMS Message，对于这种情况，数据变大是不建议的；另一个问题是Base64操作的CPU消耗会比较大，会影响到performance。因此虽然这种方法可以解决问题，但是不推荐。</p>

<p>另一个解决办法是使用IBM的ICU4J，这个API提供了很多国际化相关的工具类，使用它来重新实现我们用到的String方法，这里可以参考我写的一个工具类<a href="https://github.com/askcuix/easeframe/blob/master/modules/core/src/main/java/com/easeframe/core/lang/Unicode.java">Unicode</a>。</p>

<p>因为我们一直用Spring Batch来处理文件，便查阅了一下源码看有没有考虑到supplementary character的问题，结果这个问题也被忽视了，看来supplementary character的使用还是比较少，但如果系统需要支持多语言的环境，还是自己处理一下比较好，之后我会重写一个Spring Batch的FixLengthItemWriter，增加对supplementary character的支持。</p>

<p>这里有一些资源可供参考：</p>

<ul>
<li><a href="http://www.unicode.org">unicode.org</a></li>
<li><a href="http://www.oracle.com/technetwork/articles/javase/supplementary-142654.html">Supplementary Characters in the Java Platform</a></li>
<li><a href="http://docs.oracle.com/javase/tutorial/i18n/text/index.html">Working with Text</a></li>
</ul>

]]></content>
  </entry>
  
</feed>
