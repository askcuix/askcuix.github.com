<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Chris's Blog]]></title>
  <link href="http://askcuix.github.com/atom.xml" rel="self"/>
  <link href="http://askcuix.github.com/"/>
  <updated>2013-04-17T00:01:35+08:00</updated>
  <id>http://askcuix.github.com/</id>
  <author>
    <name><![CDATA[Chris]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[垃圾收集器及内存分配]]></title>
    <link href="http://askcuix.github.com/blog/2013/04/16/garbage-collection-and-memory-allocation/"/>
    <updated>2013-04-16T23:54:00+08:00</updated>
    <id>http://askcuix.github.com/blog/2013/04/16/garbage-collection-and-memory-allocation</id>
    <content type="html"><![CDATA[<p>程序计数器、虚拟机栈和本地方法栈的内存分配大体在编译器就可以确定，并且这些区域和线程有着相同的生命周期，在方法或线程结束时，内存也就回收了。而Java堆和方法区的内存分配和回收都是动态的，只有在程序运行期间才知道会创建哪些对象，因此是垃圾收集器所关注的内存区域。</p>

<h2>对象标记算法</h2>

<p>Java堆中存放着所有对象实例，垃圾收集器在进行回收前，需要根据算法来确定哪些对象已不再被使用，可进行回收。</p>

<h3>引用计数算法</h3>

<p>该算法是给对象添加一个引用计数器，每当有引用它时，计数器就加1；当引用失效时，计数器就减1；当计数器为0时就不能被使用了。这种算法的判定效率很高，但是很难解决Java对象之间的循环引用问题，因此未被Java语言采用。</p>

<h3>根搜索算法</h3>

<p>通过一系列的名为“GC Roots”的对象作为起始点，从这些节点开始向下搜索，搜索所走过的路径称为引用链，当一个对象当GC Roots没有任何引用链相连时，则此对象就不能被使用了。</p>

<p>可作为GC Roots的对象包括：
- 虚拟机栈中的局部变量表所引用的对象。 <br/>
- 方法区中的类静态属性引用的对象。  <br/>
- 方法区中的常量引用的对象。 <br/>
- 本地方法栈中JNI所引用的对象。</p>

<!-- more -->


<h2>Java引用</h2>

<p><strong>强引用</strong>：在代码中普遍存在的，比如“Object obj = new Object()”，只要强引用还存在，垃圾收集器则永远都不会回收引用的对象。</p>

<p><strong>软引用</strong>：一些还有用，但并非必须的对象。对于软引用关联的对象，在发生内存溢出之前，会将这些对象纳入回收范围并进行回收。</p>

<p><strong>弱引用</strong>：非必须对象，比软引用更弱一些，弱引用所关联的对象只能生存到下一次垃圾回收之前。当垃圾收集器工作时，无论当前内存是否够用，都会回收弱引用所关联的对象。</p>

<p><strong>虚引用</strong>：最弱的一种引用关系，一个对象是否被虚引用所关联，完全不会对其生存时间产生影响，也不能通过虚引用来取得对象实例，关联的唯一目的是在这个对象被垃圾回收器回收时收到一个系统通知。</p>

<h2>垃圾收集算法</h2>

<h3>标记-清除算法</h3>

<p>首先标记出所有需要回收的对象，之后统一回收所有被标记的对象。该算法效率较低，并会产生大量不连续的内存碎片。</p>

<h3>复制算法</h3>

<p>将新生代内存分为一块较大的Eden空间和两块较小的Survivor空间，每次使用Eden和其中一块Survivor，回收时将Eden和使用的Survivor中存活的对象一次性拷贝到另一块Survivor空间，然后清理Eden和之前使用的Survivor空间。</p>

<p>HotSpot虚拟机默认Eden和Survivor的大小比例是8:1，因此新生代中可用内存为整个新生代容量的90%。当Survivor空间不够用时，将依赖老年代内存进行分配担保。</p>

<h3>标记-整理算法</h3>

<p>与标记-清除算法类似，但最后步骤不是直接对可回收对象进行清除，而是将所有存活的对象都向一端移动，然后直接清理掉端边界以外的内存。</p>

<h3>分代收集算法</h3>

<p>将Java堆分为新生代和老年代，对每个年代采用合适的收集算法。</p>

<h2>垃圾收集器</h2>

<h3>Serial收集器</h3>

<p>单线程新生代收集器，在进行垃圾收集时，必须暂停所有的工作线程，导致停顿。与其它收集器的单线程相比简单高效，对于单CPU的环境没有线程交互的开销，收集效率较高。</p>

<h3>ParNew收集器</h3>

<p>新生代收集器，Serial收集器的多线程版本，是目前除Serial收集器外，唯一能够和CMS收集器配合工作的。默认开启的收集线程数与CPU的数量相同，可通过-XX:ParallelGCThreads来限制线程数。</p>

<p>ParNew收集器是使用-XX:+UseConcMarkSweepGC后的默认新生代收集器，也可以使用-XX:+UseParNewGC来强制指定。</p>

<h3>Parallel Scavenge收集器</h3>

<p>新生代收集器，以达到可控制的吞吐量为目标。可通过-XX:MaxGCPauseMillis来控制最大垃圾收集停顿时间，-XX:GCTimeRatio来控制吞吐量大小，-XX:+UseAdaptiveSizePolicy来实现自适应调节策略。</p>

<h3>Serial Old收集器</h3>

<p>Serial收集器的老年代版本。可在JDK1.5及之前版本中配合Parallel Scavenge收集器使用，也可在CMS收集器发生Concurrent Mode Failure时使用。</p>

<h3>Parallel Old收集器</h3>

<p>Parallel Scavenge收集器的老年代版本。使用多线程和“标记-整理”算法，在JDK1.6中开始提供。和Parallel Scavenge收集器配合使用非常适合注重吞吐量和CPU资源有限的场景。</p>

<h3>CMS（Concurrent Mark Sweep）收集器</h3>

<p>老年代收集器，以获取最短回收停顿时间为目标。默认启动的收集线程数是 (CPU数量+3) / 4。在并发阶段因占用一部分线程而导致应用程序变慢，总吞吐量下降。CMS收集器默认在老年代使用68%的空间后被激活，可通过调高-XX:CMSInitiatingOccupancyFraction来提高触发百分比，以降低内存回收次数。</p>

<p>若CMS运行期间预留的内存无法满足程序需要，就会出现“Concurrent Mode Failure”失败，虚拟机会临时启用Serial Old收集器来重新进行老年代的垃圾收集。</p>

<p>由于使用“标记-清除”算法会产生大量空间碎片，从而导致Full GC，可通过-XX:+UseCMSCompactAtFullCollection在Full GC后进行碎片整理。</p>

<h3>G1收集器</h3>

<p>使用“标记-整理”算法避免产生空间碎片，可以精确控制垃圾收集的时间。通过将整个Java堆划分为多个大小固定的独立区域，每次根据允许的收集时间，优先回收垃圾最多的区域，以此来保证在有限的时间内获取最高的收集效率。</p>

<h2>内存分配</h2>

<p>对象通常在新生代Eden区中分配，当Eden区没有足够空间时，将触发一次Minor GC。</p>

<p>需要大量连续内存的大对象将直接在老年代中分配，以避免新生代中发生大量的内存拷贝，可通过-XX:PretenureSizeThreshold来设置。</p>

<p>虚拟机为每个对象定义了年龄计数器，并通过Minor GC的次数来增加年龄，当达到-XX:MaxTenuringThreshold设置的阀值时，会将对象移入老年代。</p>

<p>若新生代中Survivor空间中相同年龄的对象大小总和大于Survivor空间的一半，则年龄大于或等于该年龄的对象可以直接进入老年代。</p>

<p><strong>新生代GC（Minor GC）</strong>：新生代的垃圾回收操作，Java对象的生命周期通常较短，因此Minor GC非常频繁。
<strong>老年代GC（Major GC / Full GC）</strong>：老年代的垃圾回收操作，发生Full GC通常也会发生至少一次的Minor GC，GC的速度很慢。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Korn Shell Script]]></title>
    <link href="http://askcuix.github.com/blog/2013/04/14/korn-shell-script/"/>
    <updated>2013-04-14T23:45:00+08:00</updated>
    <id>http://askcuix.github.com/blog/2013/04/14/korn-shell-script</id>
    <content type="html"><![CDATA[<h2>基本语法</h2>

<p>&#8221;;&#8221;作为语句的结束，因此可以将多个command写在一行。</p>

<pre><code> print -n "Name: "; read name; print ""
</code></pre>

<p>&#8220;&#92;&#8221; 可将第二行command与第一行连接起来，若command太长，可通过这种方式写在多行上。</p>

<pre><code> grep filename | sort -u | awk '{print $4}' | \
 uniq -c &gt;&gt; /longpath/file
</code></pre>

<h2>Variables</h2>

<p><strong>Arrays</strong></p>

<p><strong>arrname[1]=4</strong>  To fill in <br/>
<strong>print ${arraname[1]}</strong>  To print out <br/>
<strong>${arrname[*]}</strong>  Get all elements <br/>
<strong>${#arrname[*]}</strong>  Get the number of elements</p>

<!-- more -->


<h2>Branching</h2>

<p><strong>if</strong></p>

<pre><code> if [[ $value -eq 7 ]]   

 then   
    print "$value is 7"   
 fi
</code></pre>

<p><strong>if … else</strong></p>

<pre><code> if [[ $name = "John" ]]
 then
    print "Your welcome, ${name}."
 else
    print "Good bye, ${name}!"
 fi
</code></pre>

<p><strong>if &#8230; elif &#8230; else</strong></p>

<pre><code> if [[ $name = "John" ]]
 then
    print "Your welcome, ${name}."
 elif [[ $name = "Hanna" ]]
 then
    print "Hello, ${name}, who are you?"
 else
    print "Good bye, ${name}!"
 fi
</code></pre>

<p><strong>case</strong></p>

<pre><code> case $var in
   john|fred)  print $invitation;;
   martin)  print $declination;;
   *)  print "Wrong name…";;
 esac
</code></pre>

<h2>Looping</h2>

<p><strong>while</strong></p>

<pre><code> while [[ $count -gt 0 ]];do
    print "\$count is $count"
    (( count -= 1 ))
 done
</code></pre>

<p><strong>until</strong></p>

<pre><code> until [[ $answer = "yes" ]];do
    print -n "Please enter \"yes\": "
    read answer
    print ""
 done
</code></pre>

<p><strong>for</strong></p>

<pre><code> for foo in $(ls);do
    if [[ -d $foo ]];then
       print "$foo is a directory"
    else
       print "$foo is not a directory"
    fi
 done
</code></pre>

<p><strong>continue</strong></p>

<pre><code> while read line
 do
   if [[ $line = *.gz ]];then
      continue
   else
      print $line
   fi
 done
</code></pre>

<p><strong>break</strong></p>

<pre><code> while read line;do
     if [[ $line = *!(.c) ]];then
        break
     else
        print $line
     fi
 done
</code></pre>

<h2>Comparisons</h2>

<p><strong>字符比较</strong>：&#8221;=&#8221;用于相等，&#8221;!=&#8221;用于不等。 <br/>
<strong>数字比较</strong>：&#8221;-eq&#8221;用于相等，&#8221;-ne&#8221;用于不等，&#8221;-gt&#8221;用于大于，&#8221;-lt&#8221;用于小于。 <br/>
<strong>与或比较</strong>：&#8221;&amp;&amp;&#8221;表示与，&#8221;||&#8221;表示或。</p>

<h2>变量操作</h2>

<p><strong>${name##*/}</strong>：用于从包含路径的变量中取出文件名。  <br/>
<strong>${name%/*}</strong>：用于从包含路径的变量中取出路径。  <br/>
<strong>dirname</strong>：用于获取文件的路径，不包含文件名。如：dirname $0 <br/>
<strong>${foo:-4}</strong>：如果foo不存在，则返回4，但foo仍然没有值。  <br/>
<strong>${foo:=4}</strong>：如果foo不存在，则附值4给foo。  <br/>
<strong>${foo:+1}</strong>：如果foo有值，则返回1，但foo的值不改变。  <br/>
<strong>${foo:?&#8221;foo not set!&#8221;}</strong>：如果foo不存在，则退出程序并显示&#8221;foo not set!&#8221;。 <br/>
<strong>${foo:startOffset}</strong>：从startOffset处开始截取字符串foo到末尾。 <br/>
<strong>${foo:startOffset:endOffset}</strong>：截取字符串foo从startOffset到endOffset。</p>

<h2>特殊变量</h2>

<p><strong>$#</strong>：命令行参数的个数。 <br/>
<strong>$1, &#8230;.$n</strong>：单个命令行参数。 <br/>
<strong>$*</strong>：所有的命令行参数。  <br/>
<strong>$0</strong>：当前script的名字，如果是从另外一个目录执行的，还将包含路径信息。  <br/>
<strong>$?</strong>：上个command执行结果的状态。 <br/>
<strong>$$</strong>：当前script的pid。  <br/>
<strong>$!</strong>：最后一个后台执行的程序的pid。 <br/>
<strong>shift</strong>：删除第一个命令行参数。</p>

<h2>数据重定向</h2>

<p><strong>command > file</strong>：将输出写到新文件或覆盖已存在的文件。 <br/>
<strong>command >> file</strong>：将输出添加在已存在文件中。 <br/>
<strong>command 2> file</strong>：将错误输出重定向到文件。 <br/>
<strong>command 2>/dev/null</strong>：丢弃错误信息。  <br/>
<strong>command 2>&amp;1</strong>：将错误输出重定向到正常输出。  <br/>
<strong>command &lt; file</strong>：从标准输入读取文件。  <br/>
<strong>command &lt; infile > outfile</strong>：组合输入和输出重定向。</p>

<h2>Read Input from User and from Files</h2>

<p><strong>read var</strong>：读取用户输入的变量。如：</p>

<pre><code> print -n "Enter your favorite haircolor: ";read var; print ""。
</code></pre>

<p><strong>按行读取文件的内容到变量</strong>：</p>

<pre><code> { while read myeline;do
      # process $myline
 done } &lt; filename
</code></pre>

<h2>Calculation</h2>

<p>简单的计算可通过 &#8220;let&#8221; 或  (( … ))。如：(( a+=1 )) 或 let a+=1。</p>

<h2>typeset用法</h2>

<p>typeset用于设置变量属性，如大小写、宽度、左右对齐等都可以用typeset来控制, 当用typeset改变一个变量的属性时,这种改变是永久的。</p>

<p>选项：</p>

<p><strong>-u</strong>：将一个变量的字符变成大写。  <br/>
<strong>-l</strong>：将一个变量的字符变成小写。  <br/>
<strong>-L<num></strong>：将变量变成一个左对齐的num长度的字符串，有些像字符串截取。 <br/>
<strong>-R<num></strong>：将变量变成一个右对齐的num长度的字符串。 <br/>
<strong>-Z<num></strong>：将变量变成一个空格填充，占num个字符位的字符串。 <br/>
<strong>-i</strong>：强制变量为一个整数。 <br/>
<strong>-r</strong>：设置一个只读变量。</p>

<p>文件状态测试</p>

<p><strong>-b filename</strong>：当filename 存在并且是块文件时返回真。 <br/>
<strong>-c filename</strong>：当filename 存在并且是字符文件时返回真。 <br/>
<strong>-d pathname</strong>：当pathname 存在并且是一个目录时返回真。 <br/>
<strong>-e pathname</strong>：当由pathname 指定的文件或目录存在时返回真。 <br/>
<strong>-f filename</strong>：当filename 存在并且是正规文件时返回真。 <br/>
<strong>-h filename</strong>：当filename 存在并且是符号链接文件时返回真。 <br/>
<strong>-r pathname</strong>：当由pathname 指定的文件或目录存在并且可读时返回真。 <br/>
<strong>-s filename</strong>：当filename 存在并且文件大小大于0 时返回真。 <br/>
<strong>-w pathname</strong>：当由pathname 指定的文件或目录存在并且可写时返回真。 <br/>
<strong>-x pathname</strong>：当由pathname 指定的文件或目录存在并且可执行时返回真。 <br/>
<strong>-O pathname</strong>：当由pathname 存在并且被当前进程的有效用户id 的用户拥有时返回真。 <br/>
<strong>-G pathname</strong>：当由pathname 存在并且属于当前进程的有效用户id 的用户的用户组时返回真。 <br/>
<strong>file1 -nt file2</strong>：file1 比file2 新时返回真。 <br/>
<strong>file1 -ot file2</strong>：file1 比file2 旧时返回真。</p>

<h2>字符串测试</h2>

<p><strong>-z string</strong>：字符串string 为空串(长度为0)时返回真。 <br/>
<strong>-n string</strong>：字符串string 为非空串时返回真。</p>

<h2>Resources</h2>

<p><strong>Korn Shell Programming</strong>：<a href="http://www.bo.infn.it/alice/alice-doc/mll-doc/impgde/node15.html">http://www.bo.infn.it/alice/alice-doc/mll-doc/impgde/node15.html</a> <br/>
<strong>Learning the Korn Shell</strong>: <a href="http://docstore.mik.ua/orelly/unix/ksh/">http://docstore.mik.ua/orelly/unix/ksh/</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[The foundation of spring batch]]></title>
    <link href="http://askcuix.github.com/blog/2013/04/01/the-foundation-of-spring-batch/"/>
    <updated>2013-04-01T22:46:00+08:00</updated>
    <id>http://askcuix.github.com/blog/2013/04/01/the-foundation-of-spring-batch</id>
    <content type="html"><![CDATA[<p>Spring Batch是埃森哲贡献给Spring的一个开源项目，现在由双方共同维护。通过Spring Batch可以构建出轻量级的大数据量并⾏处理应⽤,⽀持事务、并发、流程、监控、纵向和横向扩展,提供统一的接口管理。Spring Batch并不包含scheduler，它只是一个通用的batch处理框架，你可以通过QuartZ，Control-M等scheduler去调用。</p>

<p>Spring Batch能够处理大批量数据的导入、导出和业务逻辑计算，执行过程无需人工干预。我们的系统是一个金融产品信息的数据中心，需要从不同的系统读取产品信息，也需要将这些信息提供给其它的系统，这种data loading就是Spring Batch的一种应用场景。</p>

<!-- more -->


<p><img src="http://askcuix.github.com/images/blog/spring_batch_common_process.png" alt="Spring Batch Common Process" /></p>

<p>上图就是Spring Batch的常用方式，从DB或是不同类型的文件中读取数据，经过转换后再写入DB或者文件。</p>

<p><img src="http://askcuix.github.com/images/blog/spring_batch_domain.png" alt="Spring Batch Domain" /></p>

<p>上图是一个Job执行的结构图，下面是对这些domain对象的简单描述，只是学习时随笔记下来的，不够详细，可以查看Spring Batch文档中的描述。</p>

<h2>Job</h2>

<p>Job是对一个batch处理流程的定义，可以简单理解为Spring中的一个Job配置，一般都包括reader和writer。</p>

<h2>JobInstance</h2>

<p>JobInstance是Job运行时产生的实例，如果这个Job是按天执行的，则每天都会创建一个JobInstance；当Job执行失败时，restart这个Job将会重用JobInstance，以便于从执行失败的地方开始重新执行。</p>

<h2>JobParameter</h2>

<p>JobParameter用于标识一个JobInstance，可以将它理解为JobInstance的ID。</p>

<h2>JobListener</h2>

<p>JobListener可以监听JobInstance生命周期中的两个事件：</p>

<p><strong>beforeJob</strong> - 在Job执行前被调用。</p>

<p><strong>afterJob</strong> - 不论Job执行成功或失败都会被调用，Job的status可以从JobExecution中获取。</p>

<h2>Parent Job</h2>

<p>对于相似的Job，可以取出相同的部分定义成一个parent Job，只需要在Job定义时添加<em>abstract=&#8221;true&#8221;</em>，然后在sub Job中通过<em>parent</em>属性来指定parent Job。</p>

<h2>JobRepository</h2>

<p>MapJobRepository通常用于测试环境或是standalone的batch。它不够稳定；不允许在不同JVM实例之间执行restart；也不能保证有相同JobParameter的两个JobInstance同时运行；它不适合在多线程Job或本地的partition step中使用。但是它仍然需要配置transaction manager，因为在Job的实现中会涉及到rollback的问题，所以可以用ResourcelessTransactionManager来代替。</p>

<h2>JobLauncher</h2>

<p>JobLauncher使用spring的taskExecutor来实现异步处理，只需要在配置中指定taskExecutor属性。如果batch是通过http request的方式触发的，那应当使用异步的方式来处理Job以避免长时间的占用链接。</p>

<h2>JobOperator</h2>

<p>JobOperator的stop()不会立刻停止一个Job，如果当前流程处理的控制权在framework，则会将StepExecution的status设置为STOPPED并保存，然后按正常的处理流程结束Job。</p>

<p>如果不希望一个restartable的Job在执行失败后restart，可以将status设置为ABORTED。</p>

<h2>JobParametersIncrementer</h2>

<p>JobParametersIncrementer可强制创建一个新的jobInstance，以避免在使用相同JobParameter时不可以再次执行Job。这只是个接口，需要自己去实现getNext()，然后在Job中定义incremented属性来引用它。</p>

<h2>Step</h2>

<p><strong>start-limit</strong>： 用于step的restart，用来控制一个start的次数。默认是Integer.MAX_VALUE。<br/>
<strong>allow-start-if-complete</strong>： 强制执行step，不管之前执行成功或失败。</p>

<h3>Skip</h3>

<p>通过指定exception来决定是否skip有问题的数据，可以结合include和exclude来定义exception列表。</p>

<p><strong>skip-limit</strong>：用来控制允许skip的数据的最大数量，在step execution中分别保存有针对read，process和write中skip的数量。</p>

<h3>Retry</h3>

<p>通过指定exception来指定是否允许重试当前有问题的错误数据，对于一些通过重试可以解决问题的数据是非常有用的，比如更新当前数据到DB时，该条数据被其它进程lock了，则在重试时可能就可以正常更新了。</p>

<p><strong>retry-limit</strong>：用来控制每个item允许重试的次数。</p>

<h3>Rollback</h3>

<p>通过指定exception来忽略rollback操作。对于Skip和Retry，如果Exception是由ItemWriter抛出的，则step中被当前transaction控制的数据会被rollback，因此要配合使用no-rollback-exception-classes来决定是否应该执行rollback。</p>

<p>Step通常会缓存Reader读入的数据，如果发生了rollback则不需要重新读入数据，但是对于一些基于transaction资源的Reader，比如从JMS queue中读取数据的Reader，JMS message也会执行rollback，则需要通过is-reader-transactional-queue来标识不需要缓存读入数据。</p>

<h2>ItemStream</h2>

<p>在Step执行失败需要restart时，可以通过ItemStream获取存储在execution之间状态信息。如果ItemReader，ItemProcessor或者ItemWriter实现了ItemStream接口，则会自动被注册在Spring Context中；否则需要单独注册streams。对于CompositeItemWriter，如果delegate的ItemWriter实现了ItemStream接口，也需要主动注册。</p>

<h2>StepListener</h2>

<p>和ItemStream一样，如果ItemReader，ItemProcessor或者ItemWriter实现了StepListener接口，则会被自动注册。</p>

<h3>StepExecutionListener</h3>

<p><strong>beforeStep</strong> - 在step执行之前调用。<br/>
<strong>afterStep</strong> - 在step结束时调用，不管执行成功或失败。可以在这里更改ExitStatus。</p>

<h3>ChunkListener</h3>

<p><strong>beforeChunk</strong> - 被调用在transaction开始后，但在ItemReader的read方法执行前。<br/>
<strong>afterChunk</strong> - chunk被commit/rollback后被调用。</p>

<p>ChunkListener也可被用在未使用chunk方式的step中，比如Tasklet， 会在tasklet执行前后被调用。</p>

<h3>ItemReadListener</h3>

<p><strong>beforeRead</strong> - 在read方法执行前被调用。<br/>
<strong>afterRead</strong> - 在read方法执行成功后被调用，并返回读到的item作为参数。<br/>
<strong>onReadError</strong> -  在read方法出现异常时被调用，并提供异常的类型作为参数。</p>

<h3>ItemProcessListener</h3>

<p><strong>beforeProcess</strong> - 在ItemProcessor的process方法执行前被调用。<br/>
<strong>afterProcess</strong> - 在process方法执行成功后被调用。<br/>
<strong>onProcessError</strong> - 在process方法出现异常时被调用，并提供item和异常作为参数。</p>

<h3>ItemWriteListener</h3>

<p><strong>beforeWrite</strong> - 在ItemWriter的write方法执行前被调用。<br/>
<strong>afterWrite</strong> - 在ItemWriter的write方法执行成功后被调用。<br/>
<strong>onWriteError</strong> - 在ItemWriter的write方法出现异常时被调用，并提供chunk data和异常作为参数。</p>

<h3>SkipListener</h3>

<p><strong>onSkipInRead</strong> - 当item在读取阶段skip时被调用。 <br/>
<strong>onSkipInProcess</strong> - 当item在process阶段skip时被调用。<br/>
<strong>onSkipInWrite</strong> -  当item在写入阶段skip时被调用，并且在transaction被commit之前。</p>

<h3>Batch Status vs. Exit Status</h3>

<p>Conditional Flow的配置中的on属性使用Exit Status，通常情况下Batch Status和Exit Status是一样的，但StepExecutionListener可以更改Exit Status。</p>

<h3>Step Scope</h3>

<p>使用Job和Step的属性延迟绑定特性时，必须将Bean的scope设置为step。使用该属性可以通过定义Spring Batch的namespace或者定义StepScope。</p>

<figure class='code'><figcaption><span>applicationContext.xml</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='xml'><span class='line'>   <span class="nt">&lt;bean</span> <span class="na">class=</span><span class="s">&quot;org.springframework.batch.core.scope.StepScope&quot;</span> <span class="nt">/&gt;</span>
</span></code></pre></td></tr></table></div></figure>


<p></p>

<h2>Resources</h2>

<p>Official site: <a href="http://www.springsource.org/spring-batch">http://www.springsource.org/spring-batch</a></p>

<p>IBM DeveloperWorks - 使用 Spring Batch 构建企业级批处理应用:<br/>
 - <a href="http://www.ibm.com/developerworks/cn/java/j-lo-springbatch1/">http://www.ibm.com/developerworks/cn/java/j-lo-springbatch1/</a><br/>
 - <a href="http://www.ibm.com/developerworks/cn/java/j-lo-springbatch2/">http://www.ibm.com/developerworks/cn/java/j-lo-springbatch2/</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Common Format of CSV Files]]></title>
    <link href="http://askcuix.github.com/blog/2013/03/26/common-format-of-csv-files/"/>
    <updated>2013-03-26T23:43:00+08:00</updated>
    <id>http://askcuix.github.com/blog/2013/03/26/common-format-of-csv-files</id>
    <content type="html"><![CDATA[<p>CSV是一种常见的文件格式，常用于不同系统之间的数据交换，对于该文件格式可以简单描述为：一组使用逗号“,”分隔字段，并以换行符作为一行数据结束的数据集合。该文件可以使用Microsoft Excel查看，但是中文字符会显示为乱码。</p>

<p>这个描述就真的只是简单描述，实际上CSV的格式处理没有这么简单。最近在和另外一个系统做集成，我们的系统会提供CSV数据文件给对方系统处理，由于我们系统中个别字段会包括换行符“CRLF”（这是遗留系统，就不用纠结为什么字段中会包含换行符了），也就是说一个字段可能会显示在几行上，但是这个字段是包含在双引号中的，结果对方系统就处理不了了。因为对方系统只是简单的按行处理数据，用逗号解析字段。</p>

<!-- more -->


<p>这种解析方式通常是没有问题，但是是不完整的。<a href="http://tools.ietf.org/html/rfc4180"><strong>RFC 4180</strong></a>是CSV格式的标准，这里提到并没有官方的规范去定义CSV的格式到底是怎样的，但是根据大多数的实现来看，应该有如下格式：</p>

<ul>
<li><p>每条数据用换行符（CRLF）分割。</p></li>
<li><p>最后一条数据可以不包含换行符。</p></li>
<li><p>可选的header行，如有的话，应该出现在第一行，并且与下面的数据有相同数量的字段。</p></li>
<li><p>在header和每条数据中，使用逗号“,”分隔字段，每一行都应该包含相同数量的字段，空白字符也可作为一个字段，一条数据的最后一个字段不应添加逗号分隔符。</p></li>
<li><p>每个字段可以包含在双引号中。</p></li>
<li><p>如果字段中包含换行符（CRLF），双引号和逗号，则必须将字段包含在双引号中。</p></li>
<li><p>如果字段中包含双引号，则除了需要将字段包含在双引号中，还要在字段中的双引号前再加一个双引号作为转义。</p></li>
</ul>


<p>由此可见，字段中是允许出现换行符的，只要该字段是包含在双引号中的。我也查阅了Spring Batch的CSV Reader的实现，也考虑到了该问题，在发现换行符的同时，也会检查当前字段是否已结束。</p>

<p>因此，我们在生成或解析CSV文件时，应该要考虑到以上特殊字符的处理，在apache的common-lang包中，也有专门针对CSV字符的转义方法，可参考<a href="http://commons.apache.org/proper/commons-lang/javadocs/api-release/org/apache/commons/lang3/StringEscapeUtils.html">StringEscapeUtils</a>，在最大程度上保证系统的robust。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[JVM运行时内存区域]]></title>
    <link href="http://askcuix.github.com/blog/2013/03/26/the-runtime-memory-of-jvm/"/>
    <updated>2013-03-26T23:31:00+08:00</updated>
    <id>http://askcuix.github.com/blog/2013/03/26/the-runtime-memory-of-jvm</id>
    <content type="html"><![CDATA[<p>Java虚拟机管理的运行时数据区域：</p>

<ul>
<li><p>程序计数器</p>

<p>是当前线程所执行的字节码的行号指示器。每条线程都有一个独立的程序计数器，各线程之间的计数器互不影响，该内存区域为线程私有，也不会出现OutOfMemoryError。</p></li>
<li><p>Java虚拟机栈</p>

<p>该区域也是线程私有，其生命周期与线程相同。虚拟机栈表述的是Java方法执行的内存模型：每个方法被执行的时候都会同时创建一个栈帧用于存储局部变量表、操作数栈、动态链接、方法出口等信息。一个方法被调用直至执行完成的过程，就对应着一个栈帧在虚拟机栈中从入栈到出栈的过程。</p>

<p><!-- more --></p>

<p>局部变量表存放了编译期可知的基本类型、对象引用（可能是一个指向对象起始地址的指针，也可能是指向一个对象的句柄，或者是与此对象相关的位置）和retuanAddress类型。64位长度的long和double类型占用2个局部变量空间，其余类型只占用1个。局部变量表所需的内存空间在编译期间完成分配，方法运行期间不会改变。</p>

<p>在本区域中，若线程请求的栈深度大于虚拟机所允许的深度，将抛出StackOverflowError；若动态扩展无法申请到足够的内存时抛出OutOfMemoryError。</p></li>
<li><p>本地方法栈</p>

<p>与虚拟机栈的作用相似，区别是虚拟机栈为虚拟机执行Java方法服务，本地方法栈为虚拟机使用到的Native方法服务。有的虚拟机实现会将虚拟机栈和本地方法栈合在一起。</p></li>
<li><p>Java堆</p>

<p>可被所有线程共享，在虚拟机启动时创建。此区域只用于存放对象实例，是垃圾收集器管理的主要区域。堆的扩展可通过-Xmx和-Xms控制。若堆中没有内存完成实例分配，也无法扩展时，将抛出OutOfMemoryError。</p></li>
<li><p>方法区</p>

<p>可被所有线程共享，用于存放已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。虚拟机规范将方法区描述为堆的一个逻辑部分。该区域很少进行垃圾回收的操作。</p>

<p>若方法区无法满足内存分配需求时，将抛出OutOfMemoryError。</p></li>
</ul>


<h2>对象访问方式</h2>

<p>虚拟机规范中未定义对象访问的方式，在主要的虚拟机实现中包含如下两种方式：</p>

<ul>
<li><p>句柄访问</p>

<p>在Java堆中划分出一块内存作为句柄池，Java栈中对象引用存储的就是对象的句柄地址，句柄中包含了对象实例数据和类型数据的地址信息。</p>

<p>这种方式在对象引用中存储的是稳定的句柄地址，在对象被移动时只会改变句柄中的实例数据指针，对象引用本身不需要被修改。</p></li>
<li><p>指针访问</p>

<p>Java栈中对象引用存储的就是对象的地址。这种方法的访问速度更快，节省了一次指针定位的开销。</p></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Supplementary Characters in Java]]></title>
    <link href="http://askcuix.github.com/blog/2013/03/15/supplementary-characters-in-java/"/>
    <updated>2013-03-15T23:37:00+08:00</updated>
    <id>http://askcuix.github.com/blog/2013/03/15/supplementary-characters-in-java</id>
    <content type="html"><![CDATA[<p>工作中经常会涉及到文件处理，而fixlength类型的文件又是一种很常见的格式。众所周知，fixlength类型的数据就是每个字段对应一行数据中固定长度的字符，每个字段都有对应的start offset和end offset，用实现来表示就是String.substring(start, end)，所以start和end的位置是至关重要的，一个字段对应错了，后面的字段就全错了。</p>

<p>在Java中使用UTF-16来表示unicode字符，一个字符就是16 bit，像String.length()就是返回有多少个16 bit。unicode支持的字符的code point范围是U+0000到U+10FFFF，这其中包括基本字符（BMP）和补充字符（supplementary character），基本字符时从U+0000到U+FFFF，补充字符从U+10000到U+10FFFF。<!-- more -->在UTF-16编码中，基本字符占用一个16 bit，而补充字符占用两个16 bit。这样Java String的很多方法就会出现问题了，当然也包括上面提到的substring和length。那么如果fixlength文件中含有补充字符，则会导致字段map错误。</p>

<p>那现在来看如何解决这个问题，一个解决办法是对字符串做Base64编码，编码之后的字符都是单个16 bit了。但是这有两个弊端，一是Base64之后会使数据变大，有时我们会将这些fixlength的数据作为JMS Message，对于这种情况，数据变大是不建议的；另一个问题是Base64操作的CPU消耗会比较大，会影响到performance。因此虽然这种方法可以解决问题，但是不推荐。</p>

<p>另一个解决办法是使用IBM的ICU4J，这个API提供了很多国际化相关的工具类，使用它来重新实现我们用到的String方法，这里可以参考我写的一个工具类<a href="https://github.com/askcuix/easeframe/blob/master/modules/core/src/main/java/com/easeframe/core/lang/Unicode.java">Unicode</a>。</p>

<p>因为我们一直用Spring Batch来处理文件，便查阅了一下源码看有没有考虑到supplementary character的问题，结果这个问题也被忽视了，看来supplementary character的使用还是比较少，但如果系统需要支持多语言的环境，还是自己处理一下比较好，之后我会重写一个Spring Batch的FixLengthItemWriter，增加对supplementary character的支持。</p>

<p>这里有一些资源可供参考：</p>

<ul>
<li><a href="http://www.unicode.org">unicode.org</a></li>
<li><a href="http://www.oracle.com/technetwork/articles/javase/supplementary-142654.html">Supplementary Characters in the Java Platform</a></li>
<li><a href="http://docs.oracle.com/javase/tutorial/i18n/text/index.html">Working with Text</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[The syntax of markdown]]></title>
    <link href="http://askcuix.github.com/blog/2013/03/10/the-syntax-of-markdown/"/>
    <updated>2013-03-10T17:36:00+08:00</updated>
    <id>http://askcuix.github.com/blog/2013/03/10/the-syntax-of-markdown</id>
    <content type="html"><![CDATA[<p>Octopress使用的是markdown语法，和wiki的语法有点相似，但又不完全相同，这里将常用的语法记录下来便于查阅。</p>

<h2>标题</h2>

<p>标题用#开头，一个#是一级标题，两个#是二级标题，#越多字体越小。</p>

<!-- more -->


<h2>换行</h2>

<p>在每一行的末尾以两个或更多个空格符号结束，然后再打回车键，即可实现 <code>&lt;br /&gt;</code>的效果。</p>

<h2>链接</h2>

<p><code>[text](link)</code>
创建文本链接。</p>

<h2>图片</h2>

<p>与链接类似，区别是前面增加叹号!：</p>

<p><code>![text](link)</code></p>

<h2>引用</h2>

<p>用<code>&gt;</code>开头的一个段落。</p>

<p>用四个空格缩进的段落，会按原始格式显示。也可以通过在引用段落的前后各加一行波浪号~~~~~~来实现。</p>

<h2>显示效果</h2>

<p>用<code>*</code>或<code>_</code>包围的文字会用斜体显示。</p>

<p>双重符号<code>**</code>或<code>__</code>则会用粗体显示。</p>

<p>用`包围的文字按代码格式显示。</p>

<h2>列表</h2>

<p>无序列表用*, +, -开头。子项缩进两个空格。</p>

<p>有序列表用数字加英文句点。</p>

<h2>水平线</h2>

<p>在一行里只放三个或更多个<code>\</code>，或<code>*</code>或<code>_</code>，就可以实现水平线标记<code>&lt;hr /&gt;</code></p>

<h2>脚注</h2>

<p>以<code>[^1]:</code> 开头，后面跟着定义。</p>

<h2>嵌入代码</h2>

<pre><code> ``` [language] [title] [url] [link text]
   code snippet
 ```
</code></pre>

<h2>转义</h2>

<p>用<code>\</code>可转义Markdown元字符。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Octopress常用命令]]></title>
    <link href="http://askcuix.github.com/blog/2013/03/10/the-common-commands-of-octopress/"/>
    <updated>2013-03-10T17:34:00+08:00</updated>
    <id>http://askcuix.github.com/blog/2013/03/10/the-common-commands-of-octopress</id>
    <content type="html"><![CDATA[<p>Octopress经常使用到的命令，在这里做个总结，方面查阅。</p>

<pre><code>rake new_post["title"]
</code></pre>

<p>创建一个post。</p>

<pre><code>rake new_page[super-awesome/page.html]
</code></pre>

<p>创建一个page。</p>

<!-- more -->


<pre><code>&lt;!-- more --&gt;
</code></pre>

<p>插入到文章当中，用来实现摘要模式。</p>

<pre><code>keywords: 
description: 
</code></pre>

<p>在post和page开头添加以上两项属性，可更改Octopress默认的keywords和description，以提高SEO。</p>

<pre><code>rake generate
</code></pre>

<p>生成post/page。</p>

<pre><code>rake preview
</code></pre>

<p>预览效果：http://localhost:4000</p>

<pre><code>rake deploy
</code></pre>

<p>deploy到github。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[New Blog Opening]]></title>
    <link href="http://askcuix.github.com/blog/2013/03/06/new-blog-opening/"/>
    <updated>2013-03-06T23:42:00+08:00</updated>
    <id>http://askcuix.github.com/blog/2013/03/06/new-blog-opening</id>
    <content type="html"><![CDATA[<p>新blog开张啦，以此博文作为纪念。</p>

<p>这些年折腾了好几个博客了，但加起来的文字总共也没有多少，我的热乎劲也就在搭建那一刹那，特别是像在GAE上要自己去折腾整个过程。所以说，我并不热衷于写博客，而是中意于搭建这样一个小站的过程。说到原因呢，可能是因为哥曾经也是个web developer，但最近几年一直在做backend，把以前的frontend功底也丢的差不多了，所以每次遇到这样的机会，总是会让我心潮澎湃。</p>

<!-- more -->


<p>Github是developer的聚集地，尤其是开源爱好者们，搭建这个blog也是为了更亲近这个社区，octopress被很多developer用来在Github上搭建blog，也想了解下，顺便沾染点geeker的感觉。</p>

<p>以前从没接触过ruby，也不知什么原因，就是对它没兴趣，我更愿意去用python，结果这次的搭建过程真叫折腾。从在Mac上安装ruby，到彻底安装上octopress，不断的遇到gcc，make，openssl等问题，不知道重试了多少遍，最后还是按照ruby China上的wiki，用了淘宝的mirror才安装成功。Linux功底不行啊，对这些问题完全束手无策。</p>

<p>不知道会在这个blog上写多少东西，准备在这里纪录一些学习笔记，平时很多东西都记录在Evernote上了，今后可以选择性的放一些在这里。前面也说过了，我并不擅长于写博客，因为我的文笔实在不咋地，写一篇拿出来见人的东西要花费很长时间，慢慢地也就没了兴趣，另一方面，自己也确实缺乏毅力，总是没能坚持写下去。我希望自己对待这个blog能有点毅力，既是对自己学习过程的监督，也是对写作能力的培养。</p>

<p><strong><em>Keep Walking……</em></strong></p>
]]></content>
  </entry>
  
</feed>
